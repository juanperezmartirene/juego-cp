"""
Aplicaci√≥n Streamlit principal para Ciudad Oriental (GM-LLM).
Interfaz para el juego de campa√±a pol√≠tica evaluado por LLM local (Ollama).
"""

import streamlit as st
import requests
import json
from pathlib import Path
import sys

# Agregar el directorio ra√≠z al path para imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.models import Evaluacion, Equipo
from app.events import obtener_evento, EVENTOS
from app.prompts import SYSTEM_PROMPT, construir_prompt_usuario, extraer_json_de_respuesta
from app.storage import guardar_evaluacion, cargar_evaluaciones, obtener_ranking


# Configuraci√≥n de p√°gina
st.set_page_config(
    page_title="Prueba de juego Ciencia Pol√≠tica",
    page_icon="üèõÔ∏è",
    layout="wide"
)

# Inicializaci√≥n de estado de sesi√≥n
if 'evaluaciones' not in st.session_state:
    st.session_state.evaluaciones = cargar_evaluaciones()

# Equipos precargados
EQUIPOS_INICIALES = [
    Equipo(
        nombre="Equipo 1",
        partido="Partido Progresista",
        candidato="Ana Mart√≠nez",
        perfil="Ex intendente, 15 a√±os en pol√≠tica, perfil moderado"
    ),
    Equipo(
        nombre="Equipo 2",
        partido="Partido Progresista",
        candidato="Carlos Ram√≠rez",
        perfil="Diputado joven, perfil m√°s radical, redes sociales fuertes"
    ),
    Equipo(
        nombre="Equipo 3",
        partido="Partido Nacional",
        candidato="Mar√≠a Fern√°ndez",
        perfil="Senadora experimentada, perfil conservador, base rural"
    ),
    Equipo(
        nombre="Equipo 4",
        partido="Partido Nacional",
        candidato="Juan L√≥pez",
        perfil="Empresario, primera vez en pol√≠tica, perfil t√©cnico"
    )
]

# T√≠tulo principal
st.title("üèõÔ∏è Prueba de juego Ciencia Pol√≠tica")
st.markdown("### Juego de Campa√±a Pol√≠tica con LLM")

# Sidebar para configuraci√≥n
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    # Modelo de Ollama
    modelo_ollama = st.text_input(
        "Modelo Ollama",
        value="qwen2.5:3b-instruct",
        help="Nombre del modelo local configurado en Ollama"
    )
    
    # URL de Ollama
    url_ollama = st.text_input(
        "URL Ollama",
        value="http://localhost:11434/api/generate",
        help="URL del endpoint de generaci√≥n de Ollama"
    )
    
    st.divider()
    
    # Selecci√≥n de etapa
    etapa = st.selectbox(
        "Etapa",
        ["Internas", "Nacional"],
        help="Etapa actual del juego"
    )
    
    # Selecci√≥n de ronda
    ronda = st.selectbox(
        "Ronda",
        ["R1", "R2", "R3", "R4", "Cierre"],
        help="Ronda actual"
    )
    
    # Informaci√≥n del evento
    try:
        evento = obtener_evento(ronda)
        st.info(f"**{evento['titulo']}**\n\n{evento['tipo_entrega']}")
    except ValueError as e:
        st.error(str(e))
        evento = None

# Contenido principal
if evento is None:
    st.error("Error al cargar el evento. Por favor, selecciona una ronda v√°lida.")
    st.stop()

# Tabs principales
tab1, tab2, tab3 = st.tabs(["üéØ Evaluar Entrega", "üìä Ranking", "üìã R√∫brica"])

with tab1:
    st.header("Evaluar Nueva Entrega")
    
    # Selecci√≥n de equipo
    equipo_seleccionado = st.selectbox(
        "Equipo",
        options=range(len(EQUIPOS_INICIALES)),
        format_func=lambda i: f"{EQUIPOS_INICIALES[i].nombre} - {EQUIPOS_INICIALES[i].candidato} ({EQUIPOS_INICIALES[i].partido})",
        help="Selecciona el equipo que presenta la entrega"
    )
    
    equipo = EQUIPOS_INICIALES[equipo_seleccionado]
    
    # Mostrar informaci√≥n del equipo
    with st.expander("üë§ Informaci√≥n del Equipo", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**Partido:** {equipo.partido}")
            st.write(f"**Candidato:** {equipo.candidato}")
        with col2:
            st.write(f"**Perfil:** {equipo.perfil}")
    
    # Visualizaci√≥n y edici√≥n del evento
    st.subheader("üìÑ Contexto del Evento")
    st.markdown(evento['descripcion'])
    
    # Campo de texto para situaci√≥n interna (editable)
    situacion_interna = st.text_area(
        "Situaci√≥n Interna del Partido",
        value="Tensiones entre corrientes hist√≥ricas y nuevas generaciones.",
        help="Describe la situaci√≥n interna actual del partido",
        height=100
    )
    
    # Campo de texto grande para la entrega
    st.subheader(f"üìù Entrega: {evento['tipo_entrega']}")
    entrega_textual = st.text_area(
        "Texto de la Entrega",
        placeholder=f"Escribe aqu√≠ tu {evento['tipo_entrega'].lower()}...",
        height=300,
        help="Ingresa el texto completo de la entrega a evaluar"
    )
    
    # Bot√≥n de evaluaci√≥n
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        evaluar = st.button("üé≤ Evaluar con GM", type="primary", use_container_width=True)
    with col2:
        if st.button("üîÑ Limpiar", use_container_width=True):
            st.rerun()
    
    # Procesamiento de evaluaci√≥n
    if evaluar:
        if not entrega_textual.strip():
            st.error("‚ö†Ô∏è Por favor, ingresa el texto de la entrega antes de evaluar.")
        else:
            with st.spinner("La ciudadan√≠a est√° evaluando..."):
                try:
                    # Construir prompt
                    prompt_usuario = construir_prompt_usuario(
                        etapa=etapa,
                        ronda=ronda,
                        evento=evento,
                        partido=equipo.partido,
                        candidato=equipo.candidato,
                        perfil=equipo.perfil,
                        situacion_interna=situacion_interna,
                        entrega_textual=entrega_textual
                    )
                    
                    # Llamada a Ollama
                    payload = {
                        "model": modelo_ollama,
                        "prompt": f"{SYSTEM_PROMPT}\n\n{prompt_usuario}",
                        "stream": False,
                        "options": {
                            "temperature": 0.5,
                            "num_predict": 1000
                        }
                    }
                    
                    response = requests.post(url_ollama, json=payload, timeout=300)
                    response.raise_for_status()
                    
                    respuesta_llm = response.json().get('response', '')
                    
                    if not respuesta_llm:
                        st.error("‚ùå El LLM no devolvi√≥ respuesta.")
                    else:
                        # Extraer JSON de la respuesta
                        json_str = extraer_json_de_respuesta(respuesta_llm)
                        
                        # Parsear evaluaci√≥n
                        evaluacion = Evaluacion.from_json(json_str)
                        
                        # Guardar en sesi√≥n y en log
                        st.session_state.evaluaciones.append(evaluacion)
                        log_file = guardar_evaluacion(
                            evaluacion=evaluacion,
                            prompt_completo=f"{SYSTEM_PROMPT}\n\n{prompt_usuario}",
                            respuesta_llm=respuesta_llm,
                            modelo_usado=modelo_ollama
                        )
                        
                        st.success(f"‚úÖ Evaluaci√≥n completada. Guardada en {log_file}")
                        st.rerun()
                
                except requests.exceptions.RequestException as e:
                    st.error(f"‚ùå Error de conexi√≥n con Ollama: {e}")
                    st.info("üí° Aseg√∫rate de que Ollama est√© corriendo y el modelo est√© disponible.")
                
                except json.JSONDecodeError as e:
                    st.error(f"‚ùå Error al parsear JSON del LLM: {e}")
                    with st.expander("üîç Ver respuesta del LLM"):
                        st.text(respuesta_llm)
                
                except ValueError as e:
                    st.error(f"‚ùå Error de validaci√≥n: {e}")
                    with st.expander("üîç Ver respuesta del LLM"):
                        st.text(respuesta_llm if 'respuesta_llm' in locals() else "No disponible")
                
                except Exception as e:
                    st.error(f"‚ùå Error inesperado: {e}")
                    st.exception(e)

    # Mostrar √∫ltima evaluaci√≥n si existe
    if st.session_state.evaluaciones:
        ultima = st.session_state.evaluaciones[-1]
        if ultima.equipo == equipo.candidato and ultima.ronda == ronda:
            st.divider()
            st.subheader("üìä √öltima Evaluaci√≥n de este Equipo en esta Ronda")
            
            # Puntajes
            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                st.metric("Claridad", ultima.scores.claridad)
            with col2:
                st.metric("Estrategia", ultima.scores.estrategia)
            with col3:
                st.metric("Credibilidad", ultima.scores.credibilidad)
            with col4:
                st.metric("Emoci√≥n/Identidad", ultima.scores.emocion_identidad)
            with col5:
                st.metric("Riesgo/Backlash", ultima.scores.riesgo_backlash)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total sin shock", ultima.total_sin_shock)
            with col2:
                st.metric("Shock opini√≥n p√∫blica", ultima.shock_opinion_publica)
            with col3:
                st.metric("Total Final", ultima.total_final, delta=f"{ultima.shock_opinion_publica:+d}")
            
            # Titular
            st.markdown(f"### üì∞ {ultima.titular}")
            
            # Esc√°ndalo
            if ultima.escandalo.visible:
                severidad_color = {
                    "Baja": "üü°",
                    "Media": "üü†",
                    "Alta": "üî¥"
                }
                st.warning(
                    f"{severidad_color.get(ultima.escandalo.severidad, '‚ö†Ô∏è')} **ESC√ÅNDALO** ({ultima.escandalo.severidad}): {ultima.escandalo.motivo}"
                )
            
            # Devoluci√≥n GM
            st.markdown("### üí¨ Devoluci√≥n de la ciudadan√≠a")
            st.markdown(ultima.devolucion_gm)
            
            # Fortalezas y debilidades
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ‚úÖ Fortalezas")
                for fortaleza in ultima.fortalezas:
                    st.write(f"‚Ä¢ {fortaleza}")
            with col2:
                st.markdown("#### ‚ùå Debilidades")
                for debilidad in ultima.debilidades:
                    st.write(f"‚Ä¢ {debilidad}")
            
            # Impacto pol√≠tico
            st.markdown("### üìà Impacto Pol√≠tico")
            impactos = ultima.impacto_politico
            cols = st.columns(5)
            impactos_data = [
                ("Instalaci√≥n", impactos.instalacion),
                ("Persuasi√≥n", impactos.persuasion),
                ("Movilizaci√≥n", impactos.movilizacion),
                ("Reputaci√≥n", impactos.reputacion),
                ("Riesgo", impactos.riesgo)
            ]
            for col, (nombre, valor) in zip(cols, impactos_data):
                with col:
                    if valor == "Sube":
                        st.success(f"{nombre}: ‚¨ÜÔ∏è")
                    elif valor == "Baja":
                        st.error(f"{nombre}: ‚¨áÔ∏è")
                    else:
                        st.info(f"{nombre}: ‚û°Ô∏è")

with tab2:
    st.header("üìä Ranking Acumulado")
    
    ranking = obtener_ranking(st.session_state.evaluaciones)
    
    if not ranking:
        st.info("üì≠ A√∫n no hay evaluaciones. Realiza tu primera evaluaci√≥n en la pesta√±a 'Evaluar Entrega'.")
    else:
        # Tabla de ranking
        for i, pos in enumerate(ranking, 1):
            with st.container():
                col1, col2, col3, col4 = st.columns([1, 3, 2, 2])
                with col1:
                    if i == 1:
                        st.markdown(f"### ü•á {i}¬∞")
                    elif i == 2:
                        st.markdown(f"### ü•à {i}¬∞")
                    elif i == 3:
                        st.markdown(f"### ü•â {i}¬∞")
                    else:
                        st.markdown(f"### {i}¬∞")
                with col2:
                    st.markdown(f"**{pos['equipo']}** ({pos['partido']})")
                with col3:
                    st.metric("Total Acumulado", pos['total_acumulado'])
                with col4:
                    st.write(f"Entregas: {pos['cantidad_entregas']}")
                st.divider()
        
        # Gr√°fico de barras (simple)
        st.subheader("Visualizaci√≥n")
        import pandas as pd
        df_ranking = pd.DataFrame(ranking)
        st.bar_chart(df_ranking.set_index('equipo')['total_acumulado'])

with tab3:
    st.header("üìã R√∫brica de Evaluaci√≥n")
    st.markdown("""
    ### Dimensiones de Evaluaci√≥n (0-20 puntos cada una)
    
    Cada entrega es evaluada en 5 dimensiones, cada una con un puntaje de 0 a 20 puntos.
    El total m√°ximo sin shock es 100 puntos.
    
    1. **Claridad** (0-20)
       - ¬øEs claro el mensaje?
       - ¬øSe entiende qu√© se propone?
       - ¬øLa comunicaci√≥n es efectiva?
    
    2. **Estrategia** (0-20)
       - ¬øLa pieza est√° bien pensada estrat√©gicamente?
       - ¬øApunta al p√∫blico correcto?
       - ¬øTiene coherencia con el contexto?
    
    3. **Credibilidad** (0-20)
       - ¬øGenera confianza?
       - ¬øEs cre√≠ble?
       - ¬øHay consistencia con el perfil del candidato?
    
    4. **Emoci√≥n/Identidad** (0-20)
       - ¬øMueve emocionalmente?
       - ¬øConecta con la identidad del p√∫blico?
       - ¬øGenera identificaci√≥n?
    
    5. **Riesgo/Backlash** (0-20)
       - ¬øQu√© tan arriesgado es?
       - ¬øPuede generar reacciones negativas?
       - Nota: Un puntaje ALTO en esta dimensi√≥n indica M√ÅS riesgo (no es positivo)
    
    ### Shock de Opini√≥n P√∫blica (-3 a +3)
    
    Un ajuste peque√±o que refleja reacciones inesperadas de la opini√≥n p√∫blica y los medios.
    Puede ser positivo o negativo, pero siempre debe estar justificado por el contexto.
    
    **Total Final = Suma de scores (0-100) + Shock (-3 a +3)**
    
    ### Esc√°ndalo
    
    Si la entrega contiene elementos problem√°ticos que puedan generar controversia p√∫blica:
    - **Visible**: S√≠/No
    - **Severidad**: Baja, Media o Alta
    - **Motivo**: Breve descripci√≥n
    
    ### Impacto Pol√≠tico
    
    Eval√∫a el impacto en 5 dimensiones cualitativas:
    - **Instalaci√≥n**: Sube / Baja / Se mantiene
    - **Persuasi√≥n**: Sube / Baja / Se mantiene
    - **Movilizaci√≥n**: Sube / Baja / Se mantiene
    - **Reputaci√≥n**: Sube / Baja / Se mantiene
    - **Riesgo**: Sube / Baja / Se mantiene
    """)

# Footer
st.divider()
st.markdown(
    "<div style='text-align: center; color: gray;'>Ciudad Oriental (GM-LLM) - Prototipo Educativo</div>",
    unsafe_allow_html=True
)

